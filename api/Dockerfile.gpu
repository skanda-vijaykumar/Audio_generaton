# API Dockerfile (GPU) â€” Dia TTS FastAPI server with CUDA support
# Build:  docker compose -f docker-compose.yaml -f docker-compose.gpu.yaml up --build
# Requires NVIDIA Container Toolkit on host.

FROM nvidia/cuda:12.1.1-runtime-ubuntu22.04

ENV DEBIAN_FRONTEND=noninteractive

RUN apt-get update && apt-get install -y \
    python3 python3-pip python3-venv \
    libsndfile1 \
    ffmpeg \
    && apt-get clean && rm -rf /var/lib/apt/lists/* \
    && ln -sf /usr/bin/python3 /usr/bin/python

RUN useradd -m -u 1001 appuser && \
    mkdir -p /app/tmp/uploads /app/tmp/outputs \
             /app/models/cache && \
    chown -R appuser:appuser /app

WORKDIR /app

# Install CUDA-enabled PyTorch, then the rest of the deps.
# --extra-index-url lets torch deps (typing-extensions, jinja2 etc.) resolve from PyPI.
COPY api/requirements.txt /app/api/requirements.txt
RUN pip install --no-cache-dir \
    torch==2.5.1+cu121 torchaudio==2.5.1+cu121 \
    --extra-index-url https://download.pytorch.org/whl/cu121 && \
    pip install --no-cache-dir -r /app/api/requirements.txt

# Copy backend (the Dia model code) and API code
COPY backend/ /app/backend/
COPY api/ /app/api/

RUN chown -R appuser:appuser /app
USER appuser

ENV PYTHONUNBUFFERED=1 \
    PYTHONPATH=/app \
    HF_HOME=/app/models/cache \
    TRANSFORMERS_CACHE=/app/models/cache \
    HF_HUB_CACHE=/app/models/cache/hub \
    DIA_HOST=0.0.0.0 \
    DIA_PORT=8000 \
    DIA_UPLOAD_DIR=/app/tmp/uploads \
    DIA_OUTPUT_DIR=/app/tmp/outputs

EXPOSE 8000

CMD ["python", "-m", "api.run"]
